{
 "metadata": {
  "name": "",
  "signature": "sha256:d328aa471ba3947e27357bc12a9ca8472cf6eec1774d61677aefdfe9cf823d5e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Description\n",
      "In this lab session we will build a simple recommender for movies. During the process we will have the opportunity to practice data manipulation, sparse linear algebra and the Python data analysis ecosystem.\n",
      "\n",
      "We will be using the following libraries\n",
      "\n",
      "* **pandas**: The de-facto data manipulation library for Python. Based con the concept of a `DataFrame` (similar to R's). Provides a lot of functionality for importing / exporting data, filtering, transformations, \\ldots\n",
      "* **numpy**: Vector and matrix operations. Wraps highly optimised C / Fortran libraries, so it offers very good performance.\n",
      "* **pylab**: For plotting and visualising the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "import seaborn as sns  # Better looking defaults for plots (optional)\n",
      "from datetime import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loading the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read the ratings\n",
      "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None)\n",
      "ratings.columns = ['user', 'item', 'rating', 'ts']\n",
      "# Parse the timestamps\n",
      "ratings['ts'] = ratings['ts'].map(datetime.fromtimestamp)\n",
      "# Read the movie ID - name mapping\n",
      "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None)\n",
      "movies.columns = ['item', 'title', 'genre']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Basic investigations\n",
      "Let's get some basic descriptive statistics about the distribution of the ratings. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ratings['rating'].describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's calculate the frequency of each rating and plot it in a histogram"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rating_hist = ...\n",
      "rating_hist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "pl.bar(rating_hist.index.values - 0.5, rating_hist.values)\n",
      "pl.title('Histogram of ratings')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Movie popularity"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's try a slightly more fine-grained analysis. Let's look at the ratings once aggregated per movie. Specifically, plot the histogram of the number of ratings per movie and the histogram of the average rating per movie. For the latter, include only movies with a substantial number of ratings (e.g. >10) for a more robust characterisation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# num_ratings_per_movie = ...."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# avg_rating_per_movie = ...."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Train / test split"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to be able to characterise the performance of our recommender system we need to split the data into train and test subsets so that evaluation can be performed on samples that were not used during the learning process. We are also going to pre-filter the dataset to use only relatively popular movies. First, create a new DataFrame called `subset` which only contains information about movies with more than 25 ratings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# subset = ..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now create two DataFrames `ratings_test` and `ratings_train`. They should form a random, non-overlapping partition of `subset`. Let `ratings_train` contain 20000 ratings.\n",
      "\n",
      "HINT: You can use Numpy's np.random.choice function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TRAIN_SIZE = 20000\n",
      "#ratings_test = ...\n",
      "#ratings_train = "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Modeling the ratings\n",
      "\n",
      "Let's start with a very simple model\n",
      "\n",
      "$$\n",
      "\\hat{r}_{ij} = \\mu + b^{(u)}(i) + b^{(i)}(j)\n",
      "$$\n",
      "\n",
      "where $b^{(u)}$ is a vector containing per-user biases, $b^{(i)}$ contains per-item biases and $\\mu$ is a global bias. Obviously we can drop the $\\mu$ term if we first make the ratings zero-mean so that we can define\n",
      "\n",
      "$$\n",
      "\\tilde{r}_{ij} = r_{ij} - \\mu = r_{ij} - \\frac{1}{N}\\sum_{(x,y) \\in \\mathcal{D}} r_{x,y}\n",
      "$$\n",
      "\n",
      "In the next cell, add a new column to the `ratings` DataFrame called `rating_n` which contains a zero-mean version of the original ratings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ratings['rating_n'] = ..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's check that the column is actually zero-mean"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's check\n",
      "assert(abs(ratings['rating_n'].mean()) < 1e-5)\n",
      "ratings['rating_n'].describe()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Great! Let's see what's our baseline MSE using just this global bias term\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "global_mse = (ratings['rating_n'] ** 2).mean()\n",
      "print \"MSE with just a global bias term: %.3f\" % global_mse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Learning user and item biases\n",
      "So now we can user $\\tilde{r}_{ij}$ as our targets and simplify our model to\n",
      "\n",
      "$$\n",
      "\\hat{r}_{ij} = b^{(u)}(i) + b^{(i)}(j)\n",
      "$$\n",
      "\n",
      "How can we learn the bias parameters $b^{(u)}$ and $b^{(i)}$? The usual solution implies simply closed-form minimization of the residuals of previous effects (see e.g. Sec 2.1 of [this survey](http://files.grouplens.org/papers/FnT%20CF%20Recsys%20Survey.pdf))\n",
      "\n",
      "$$\n",
      "b^{(u)} = \\frac{1}{|I(i)| + \\gamma}\\sum_{j \\in I(i)} (\\tilde{r}_{ij}) \\\\\n",
      "b^{(i)} = \\frac{1}{|U(j)| + \\gamma}\\sum_{i \\in U(j)} (\\tilde{r}_{ij} - b^{(u)}(i))\n",
      "$$\n",
      "\n",
      "where $\\gamma$ is a regularisation term, $I(i)$ is the set of items that have been rated by user $i$ and $U(j)$ is the set of users that have rated item $j$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gamma = 25 # Regularisation factor (a.k.a. magic number)\n",
      "sum_cnt = ratings.groupby('user')['rating_n'].agg({\"sum\": np.sum, \"count\": len})\n",
      "b_u = sum_cnt['sum'] / (sum_cnt['count'] + gamma)\n",
      "b_u.name = 'b_u'\n",
      "wip = ratings.merge(b_u.reset_index(), on='user')\n",
      "wip.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Regularised bias estmation\n",
      "wip['residual'] = wip['rating_n'] - wip['b_u']\n",
      "sum_cnt = wip.groupby('item')['residual'].agg({\"sum\": np.sum, \"count\": len})\n",
      "b_i = sum_cnt['sum'] / (sum_cnt['count'] + r)\n",
      "b_i.name = 'b_i'\n",
      "wip = wip.merge(b_i.reset_index(), on='item')\n",
      "wip.head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wip['pred_baseline'] = wip['b_u'] + wip['b_i']\n",
      "#pred_baseline.name = 'pred_baseline'\n",
      "\n",
      "ratings_with_pred = ratings.merge(wip[['user','item','pred_baseline']], on=['user','item'])\n",
      "ratings_with_pred.head(10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's make sure that our new model which incorporates per-user and per-item biases represents the original dataset more accurately."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Error calculation\n",
      "ratings_with_pred['res_baseline'] = ratings_with_pred['rating_n'] - ratings_with_pred['pred_baseline']\n",
      "mse_baseline = (ratings_with_pred['res_baseline'] ** 2).mean()\n",
      "print \"MSE with user / item /gobal biases: %.3f\" % mse_baseline                            \n",
      "                                    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Obviously the reconstruction error on the training set is not that informative about the real-world performance of a model. Let's check now the error on the test set that we prepared earlier. Calculate both the MSE and the reduction in variance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_bound = ratings['user'].max() + 1\n",
      "item_bound = ratings['item'].max() + 1\n",
      "\n",
      "b_u_v = b_u.reindex(np.arange(user_bound)).fillna(0).values\n",
      "b_i_v = b_i.reindex(np.arange(item_bound)).fillna(0).values\n",
      "B_u = b_u_v[:, np.newaxis].repeat(item_bound, 1)\n",
      "B_i = b_i_v[np.newaxis, :].repeat(user_bound, 0)\n",
      "P_basic = B_u + B_i\n",
      "\n",
      "pred = np.zeros(len(ratings_test))\n",
      "i = 0\n",
      "\n",
      "pred = P_basic[ratings_test['user'], ratings_test['item']]\n",
      "\n",
      "signal = ratings_test['rating'].std()\n",
      "print \"MSE on the test set: %.3f\"% ((ratings_test['rating'] - ratings_test['rating'].mean() - pred)**2).mean()\n",
      "print \"Variance reduction on test set: %.3f%%\" % ((1 - ((ratings_test['rating'] - ratings_test['rating'].mean() - pred) ** 2).mean()/signal) * 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How does the result look like? Is it similar to the error on the training set? Is that a good sign?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Latent variables / matrix factorisation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now try to capture the variance unexplained by the user / item biases using a latent space representation. The model that we are after is given by:\n",
      "\n",
      "$$\n",
      "\\hat{r}_{ij} = b^{(u)}(i) + b^{(i)}(j) + \\sum_{d=1}^D w_{id}v_{jd} = b^{(u)}(i) + b^{(i)}(j) + w_i^Tv_j\n",
      "$$\n",
      "\n",
      "where w_i and v_j are the *latent representations* of user $i$ and item $j$ respectively. We can learn those latent representations by factorising the residual matrix (i.e. the matrix of the difference between the actual rankings and our bias-based estimates). The natural choice for the job is the Singular Value Decomposition (SVD). Moreover, since our rating matrix is sparse (there are a lot of (user, item) pairs for which we have no rating) we should use sparse matrix representations. Luckily for us, the `scipy` package provides sparse linear algebra functionality out of the box in the `svds` function, wrapping the well-known `ARPACK` library."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.sparse.csc import csc_matrix\n",
      "from scipy.sparse.linalg import svds\n",
      "\n",
      "# Construct a sparse matrix of ratings\n",
      "# M = csc_matrix( ... )\n",
      "\n",
      "# Sparse SVD\n",
      "D = 10  # Latent space dimension\n",
      "[W,U,V] = svds(M, D)\n",
      "# Now obtain the reconstructed matrix\n",
      "# M_rec = ...."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pred_svd_train = ..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ratings_with_pred['pred_svd'] = pred_svd_train\n",
      "ratings_with_pred['res_svd'] = ratings_with_pred['rating_n'] - ratings_with_pred['pred_svd']\n",
      "mse_svd_train = (ratings_with_pred['res_svd'] ** 2).mean()\n",
      "print \"Mean square error with SVD decomposition (%i dimensions) on training set: %f \" % (D, mse_svd_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's now evaluate the performance on the test set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_svd_test = P_svd[ratings_test['user'], ratings_test['item']]\n",
      "err_test = ratings_test['rating'] - pred_svd_test - ratings_test['rating'].mean()\n",
      "mse_svd_test = (err_test ** 2).mean()\n",
      "print \"MSE with SVD decomposition on test set: %.3f\" % mse_svd_test\n",
      "print \"Variance reduction: %.3f%%\"  % ((1 - ((ratings_test['rating'] - ratings_test['rating'].mean() - pred_svd_test) ** 2).mean()/signal) * 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Repeat the process above for several latent space dimensionalities and plot the test set MSE."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for d in ...."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's now explore the predictions. First let's look at our predictions for a user's favorite films"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "USER = 200  # Pick your favorite\n",
      "user_ratings = ratings_with_pred[ratings_with_pred['user'] == USER]\n",
      "user_ratings = user_ratings[['user','item','rating','pred_baseline','pred_svd']]\n",
      "user_ratings = pd.merge(user_ratings, movies, on='item')\n",
      "user_ratings.sort('pred_svd', ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now let's see what the model suggests as the best and worst recommendations for that user"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_pred = np.argsort(P_svd[USER, :])\n",
      "top_films = sorted_pred[-20:]\n",
      "worst_films = sorted_pred[:20]\n",
      "print \"Top picks\"\n",
      "movies[movies['item'].isin(top_films)]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Bottom picks\"\n",
      "movies[movies['item'].isin(worst_films)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Do some more exploration on your own before going on to the extra questions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Extra questions\n",
      "\n",
      "## Leveraging the genre information\n",
      "Can you think of any way to use the genre information to improve the recommender system performance?\n",
      "\n",
      "## Leveraging time information\n",
      "Can you think of any way of using the timestamp?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}